{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "924a0aae-113a-4967-b0be-04f3ff3403a2",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA) on House Prices Dataset\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this project, we will perform **Exploratory Data Analysis (EDA)** on the **House Prices: Advanced Regression Techniques** dataset from Kaggle. The goal of EDA is to understand the dataset by examining its structure, cleaning the data, and visualizing key features. This process will help us uncover important patterns and relationships in the data, and provide insights into which features might be useful for predictive modeling in future steps.\n",
    "\n",
    "We will follow these 7 key steps throughout the analysis:\n",
    "\n",
    "### Steps of the EDA Process\n",
    "\n",
    "1. **Understanding the Data**: This includes looking at the data types of various columns, understanding what each column represents, and identifying any key columns.\n",
    "2. **Summary Statistics**: Calculating basic statistics like mean, median, mode, standard deviation, and range for numerical columns.\n",
    "3. **Data Cleaning**: Identifying and handling missing values, outliers, and any inconsistencies in the data.\n",
    "4. **Data Visualization**: Creating visualizations such as histograms, box plots, scatter plots, and correlation matrices to get a sense of the distributions, relationships, and patterns in the data.\n",
    "5. **Feature Engineering**: Creating new features or modifying existing ones to better capture the underlying patterns in the data.\n",
    "6. **Identifying Trends and Patterns**: Using the summary statistics and visualizations to identify any obvious trends, patterns, or anomalies in the data.\n",
    "7. **Initial Hypothesis Testing**: Formulating and testing initial hypotheses about the data based on the observations from the EDA.\n",
    "\n",
    "---\n",
    "\n",
    "Let's begin by loading the dataset and reviewing its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ed6f675-8da5-465f-8d27-0a13ad6aa6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c28106-6de6-466b-ac61-86afba9c5ba7",
   "metadata": {},
   "source": [
    "## Understanding the Data ##\n",
    "For the first step of Exploratory Data Analysis (EDA), we'll begin by familiarizing ourselves with the structure of the dataset and the information provided. This involves inspecting the first few rows to understand the general structure (columns and data types).\n",
    "in this case we also have a very helpful accompanying documentation (data_description.txt) to understand the meaning of each column.\n",
    "Identifying key columns that may have important roles in the analysis, based on the data description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1073da37-75fd-4ebf-a155-6b11237c3b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
      "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
      "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
      "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
      "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
      "\n",
      "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
      "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
      "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
      "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
      "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
      "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
      "\n",
      "  YrSold  SaleType  SaleCondition  SalePrice  \n",
      "0   2008        WD         Normal     208500  \n",
      "1   2007        WD         Normal     181500  \n",
      "2   2008        WD         Normal     223500  \n",
      "3   2006        WD        Abnorml     140000  \n",
      "4   2008        WD         Normal     250000  \n",
      "\n",
      "[5 rows x 81 columns]\n",
      "\n",
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1460 non-null   int64  \n",
      " 1   MSSubClass     1460 non-null   int64  \n",
      " 2   MSZoning       1460 non-null   object \n",
      " 3   LotFrontage    1201 non-null   float64\n",
      " 4   LotArea        1460 non-null   int64  \n",
      " 5   Street         1460 non-null   object \n",
      " 6   Alley          91 non-null     object \n",
      " 7   LotShape       1460 non-null   object \n",
      " 8   LandContour    1460 non-null   object \n",
      " 9   Utilities      1460 non-null   object \n",
      " 10  LotConfig      1460 non-null   object \n",
      " 11  LandSlope      1460 non-null   object \n",
      " 12  Neighborhood   1460 non-null   object \n",
      " 13  Condition1     1460 non-null   object \n",
      " 14  Condition2     1460 non-null   object \n",
      " 15  BldgType       1460 non-null   object \n",
      " 16  HouseStyle     1460 non-null   object \n",
      " 17  OverallQual    1460 non-null   int64  \n",
      " 18  OverallCond    1460 non-null   int64  \n",
      " 19  YearBuilt      1460 non-null   int64  \n",
      " 20  YearRemodAdd   1460 non-null   int64  \n",
      " 21  RoofStyle      1460 non-null   object \n",
      " 22  RoofMatl       1460 non-null   object \n",
      " 23  Exterior1st    1460 non-null   object \n",
      " 24  Exterior2nd    1460 non-null   object \n",
      " 25  MasVnrType     588 non-null    object \n",
      " 26  MasVnrArea     1452 non-null   float64\n",
      " 27  ExterQual      1460 non-null   object \n",
      " 28  ExterCond      1460 non-null   object \n",
      " 29  Foundation     1460 non-null   object \n",
      " 30  BsmtQual       1423 non-null   object \n",
      " 31  BsmtCond       1423 non-null   object \n",
      " 32  BsmtExposure   1422 non-null   object \n",
      " 33  BsmtFinType1   1423 non-null   object \n",
      " 34  BsmtFinSF1     1460 non-null   int64  \n",
      " 35  BsmtFinType2   1422 non-null   object \n",
      " 36  BsmtFinSF2     1460 non-null   int64  \n",
      " 37  BsmtUnfSF      1460 non-null   int64  \n",
      " 38  TotalBsmtSF    1460 non-null   int64  \n",
      " 39  Heating        1460 non-null   object \n",
      " 40  HeatingQC      1460 non-null   object \n",
      " 41  CentralAir     1460 non-null   object \n",
      " 42  Electrical     1459 non-null   object \n",
      " 43  1stFlrSF       1460 non-null   int64  \n",
      " 44  2ndFlrSF       1460 non-null   int64  \n",
      " 45  LowQualFinSF   1460 non-null   int64  \n",
      " 46  GrLivArea      1460 non-null   int64  \n",
      " 47  BsmtFullBath   1460 non-null   int64  \n",
      " 48  BsmtHalfBath   1460 non-null   int64  \n",
      " 49  FullBath       1460 non-null   int64  \n",
      " 50  HalfBath       1460 non-null   int64  \n",
      " 51  BedroomAbvGr   1460 non-null   int64  \n",
      " 52  KitchenAbvGr   1460 non-null   int64  \n",
      " 53  KitchenQual    1460 non-null   object \n",
      " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 55  Functional     1460 non-null   object \n",
      " 56  Fireplaces     1460 non-null   int64  \n",
      " 57  FireplaceQu    770 non-null    object \n",
      " 58  GarageType     1379 non-null   object \n",
      " 59  GarageYrBlt    1379 non-null   float64\n",
      " 60  GarageFinish   1379 non-null   object \n",
      " 61  GarageCars     1460 non-null   int64  \n",
      " 62  GarageArea     1460 non-null   int64  \n",
      " 63  GarageQual     1379 non-null   object \n",
      " 64  GarageCond     1379 non-null   object \n",
      " 65  PavedDrive     1460 non-null   object \n",
      " 66  WoodDeckSF     1460 non-null   int64  \n",
      " 67  OpenPorchSF    1460 non-null   int64  \n",
      " 68  EnclosedPorch  1460 non-null   int64  \n",
      " 69  3SsnPorch      1460 non-null   int64  \n",
      " 70  ScreenPorch    1460 non-null   int64  \n",
      " 71  PoolArea       1460 non-null   int64  \n",
      " 72  PoolQC         7 non-null      object \n",
      " 73  Fence          281 non-null    object \n",
      " 74  MiscFeature    54 non-null     object \n",
      " 75  MiscVal        1460 non-null   int64  \n",
      " 76  MoSold         1460 non-null   int64  \n",
      " 77  YrSold         1460 non-null   int64  \n",
      " 78  SaleType       1460 non-null   object \n",
      " 79  SaleCondition  1460 non-null   object \n",
      " 80  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n",
      "None\n",
      "\n",
      "Summary statistics for numerical columns:\n",
      "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
      "count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n",
      "mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n",
      "std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n",
      "min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n",
      "25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n",
      "50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n",
      "75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n",
      "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
      "\n",
      "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\n",
      "count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000  ...   \n",
      "mean      5.575342  1971.267808   1984.865753   103.685262   443.639726  ...   \n",
      "std       1.112799    30.202904     20.645407   181.066207   456.098091  ...   \n",
      "min       1.000000  1872.000000   1950.000000     0.000000     0.000000  ...   \n",
      "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000  ...   \n",
      "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000  ...   \n",
      "75%       6.000000  2000.000000   2004.000000   166.000000   712.250000  ...   \n",
      "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000  ...   \n",
      "\n",
      "        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\n",
      "count  1460.000000  1460.000000    1460.000000  1460.000000  1460.000000   \n",
      "mean     94.244521    46.660274      21.954110     3.409589    15.060959   \n",
      "std     125.338794    66.256028      61.119149    29.317331    55.757415   \n",
      "min       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
      "50%       0.000000    25.000000       0.000000     0.000000     0.000000   \n",
      "75%     168.000000    68.000000       0.000000     0.000000     0.000000   \n",
      "max     857.000000   547.000000     552.000000   508.000000   480.000000   \n",
      "\n",
      "          PoolArea       MiscVal       MoSold       YrSold      SalePrice  \n",
      "count  1460.000000   1460.000000  1460.000000  1460.000000    1460.000000  \n",
      "mean      2.758904     43.489041     6.321918  2007.815753  180921.195890  \n",
      "std      40.177307    496.123024     2.703626     1.328095   79442.502883  \n",
      "min       0.000000      0.000000     1.000000  2006.000000   34900.000000  \n",
      "25%       0.000000      0.000000     5.000000  2007.000000  129975.000000  \n",
      "50%       0.000000      0.000000     6.000000  2008.000000  163000.000000  \n",
      "75%       0.000000      0.000000     8.000000  2009.000000  214000.000000  \n",
      "max     738.000000  15500.000000    12.000000  2010.000000  755000.000000  \n",
      "\n",
      "[8 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 3: Display the first few rows of the dataset to get a general overview\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Step 4: Output the summary of the dataset (columns and data types)\n",
    "print(\"\\nDataset Information:\")\n",
    "print(df.info())\n",
    "\n",
    "# Step 5: Output summary statistics for numerical columns\n",
    "print(\"\\nSummary statistics for numerical columns:\")\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1adad20-0b6f-406b-890a-94d68c6e8396",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Data cleaning is an essential step in preparing our dataset for analysis. In this section, we will handle missing values, deal with inconsistencies, and prepare the data for further analysis.\n",
    "\n",
    "### 1. Handle Missing Values\n",
    "\n",
    "First, we need to check which columns contain missing values and how we can handle them. Missing values can be dropped, imputed with mean/median/mode, or treated in other ways depending on the data type and context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "852018ab-2771-4ddb-9a49-b8fde2e6924c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values and their percentages:\n",
      "              Missing Values  % of Total Values\n",
      "PoolQC                  1453          99.520548\n",
      "MiscFeature             1406          96.301370\n",
      "Alley                   1369          93.767123\n",
      "Fence                   1179          80.753425\n",
      "MasVnrType               872          59.726027\n",
      "FireplaceQu              690          47.260274\n",
      "LotFrontage              259          17.739726\n",
      "GarageYrBlt               81           5.547945\n",
      "GarageCond                81           5.547945\n",
      "GarageType                81           5.547945\n",
      "GarageFinish              81           5.547945\n",
      "GarageQual                81           5.547945\n",
      "BsmtFinType2              38           2.602740\n",
      "BsmtExposure              38           2.602740\n",
      "BsmtQual                  37           2.534247\n",
      "BsmtCond                  37           2.534247\n",
      "BsmtFinType1              37           2.534247\n",
      "MasVnrArea                 8           0.547945\n",
      "Electrical                 1           0.068493\n",
      "Removed columns (more than 50% missing data): ['Alley', 'MasVnrType', 'PoolQC', 'Fence', 'MiscFeature']\n",
      "Missing values in column 'LotFrontage' replaced by the median: 69.0\n",
      "Missing values in column 'MasVnrArea' replaced by the median: 0.0\n",
      "Missing values in column 'GarageYrBlt' replaced by the median: 1980.0\n",
      "Missing values in column 'BsmtQual' replaced by the mode: 'TA'\n",
      "Missing values in column 'BsmtCond' replaced by the mode: 'TA'\n",
      "Missing values in column 'BsmtExposure' replaced by the mode: 'No'\n",
      "Missing values in column 'BsmtFinType1' replaced by the mode: 'Unf'\n",
      "Missing values in column 'BsmtFinType2' replaced by the mode: 'Unf'\n",
      "Missing values in column 'Electrical' replaced by the mode: 'SBrkr'\n",
      "Missing values in column 'FireplaceQu' replaced by the mode: 'Gd'\n",
      "Missing values in column 'GarageType' replaced by the mode: 'Attchd'\n",
      "Missing values in column 'GarageFinish' replaced by the mode: 'Unf'\n",
      "Missing values in column 'GarageQual' replaced by the mode: 'TA'\n",
      "Missing values in column 'GarageCond' replaced by the mode: 'TA'\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing values in the dataset\n",
    "missing_data = df.isnull().sum().sort_values(ascending=False)\n",
    "missing_percentage = (df.isnull().sum() / df.isnull().count() * 100).sort_values(ascending=False)\n",
    "missing_data_table = pd.concat([missing_data, missing_percentage], axis=1, keys=['Missing Values', '% of Total Values'])\n",
    "\n",
    "# Display the columns with missing values\n",
    "print(\"Columns with missing values and their percentages:\")\n",
    "print(missing_data_table[missing_data_table['Missing Values'] > 0])\n",
    "\n",
    "# Handle missing values:\n",
    "# - Drop columns where more than 50% of the data is missing\n",
    "# - For numerical columns, we can impute missing values with the median.\n",
    "# - For categorical columns, we can impute missing values with the mode.\n",
    "\n",
    "# Drop columns where more than 50% of data is missing\n",
    "threshold = 0.5 * len(df)\n",
    "removed_columns = df.columns[df.isnull().sum() > threshold].tolist()\n",
    "\n",
    "# Drop columns where more than 50% of data is missing\n",
    "df = df.drop(columns=removed_columns)\n",
    "\n",
    "# Print the list of removed columns\n",
    "if removed_columns:\n",
    "    print(f\"Removed columns (more than 50% missing data): {removed_columns}\")\n",
    "else:\n",
    "    print(\"No columns were removed due to missing data.\")\n",
    "\n",
    "# Replace missing values in numerical columns with the median and print the details\n",
    "for col in df.select_dtypes(include=['float64', 'int64']):\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        median_value = df[col].median()\n",
    "        df[col] = df[col].fillna(median_value)\n",
    "        print(f\"Missing values in column '{col}' replaced by the median: {median_value}\")\n",
    "\n",
    "# Replace missing values in categorical columns with the mode and print the details\n",
    "for col in df.select_dtypes(include=['object']):\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        mode_value = df[col].mode()[0]\n",
    "        df[col] = df[col].fillna(mode_value)\n",
    "        print(f\"Missing values in column '{col}' replaced by the mode: '{mode_value}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dee2e3-dc75-495d-8b7c-cf7e94b32ee4",
   "metadata": {},
   "source": [
    "### 2. Handle Inconsistent Data Types\n",
    "\n",
    "Often, datasets have columns with inconsistent or incorrect data types (e.g., numerical data stored as strings). We will ensure that each column has the correct data type.\n",
    "\n",
    "??convert to 'category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea11a5c0-0c1b-487a-881d-5823bcf92982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert MSSubClass to a categorical variable as it represents a class, not a numerical value\n",
    "#df['MSSubClass'] = df['MSSubClass'].astype('category')\n",
    "\n",
    "# Find and display examples of mixed data types within a column\n",
    "for col in df.columns:\n",
    "    mixed_types = df[col].apply(type).nunique() > 1  # Check if there are more than one data type\n",
    "    if mixed_types:\n",
    "        # Get the unique data types in the column\n",
    "        unique_types = df[col].apply(type).unique()\n",
    "        \n",
    "        # Print column name and the different types found\n",
    "        print(f\"Column '{col}' contains mixed data types: {unique_types}\")\n",
    "        \n",
    "        # Display examples of each data type\n",
    "        print(f\"Examples of different types in column '{col}':\")\n",
    "        for data_type in unique_types:\n",
    "            examples = df[col][df[col].apply(lambda x: isinstance(x, data_type))].head(3).tolist()\n",
    "            print(f\" - {data_type}: {examples}\")\n",
    "        print()  # Blank line for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5434c6f9-b555-4494-ba18-a2d6c0bd899f",
   "metadata": {},
   "source": [
    "todo: correct types based on data_description.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a643ee-96b7-468d-a48d-c07a1f97765c",
   "metadata": {},
   "source": [
    "### 3. Handle Outliers\n",
    "\n",
    "Outliers can distort the analysis, especially in regression tasks. We will detect and handle outliers using the IQR (Interquartile Range) method for continuous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0949e37-bd30-4a49-b986-79d56d91e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove outliers using IQR (Interquartile Range)\n",
    "def remove_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    # Remove rows with outliers\n",
    "    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# Apply the function to key continuous columns\n",
    "# For example, removing outliers from 'GrLivArea' and 'LotArea'\n",
    "df = remove_outliers(df, 'GrLivArea')\n",
    "df = remove_outliers(df, 'LotArea')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65785296-8943-43c2-a500-2842fbbfa547",
   "metadata": {},
   "source": [
    "### 4. Standardize Categorical Variables\n",
    "\n",
    "Categorical variables often need to be standardized or encoded for analysis. In this step, we will handle categorical variables by encoding them into numerical representations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f6c625-b4ae-4ff7-842c-c577243a8ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Standardizing Categorical Variables\n",
    "\n",
    "# Use one-hot encoding for categorical variables\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# Display the updated dataframe\n",
    "print(\"Updated dataframe after one-hot encoding:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b000bec5-90b3-4415-a870-34b2ffba1f14",
   "metadata": {},
   "source": [
    "### 5. Final Check\n",
    "\n",
    "After performing the cleaning steps, we'll do a final check to ensure there are no remaining missing values or inconsistencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05859e8f-99f6-40db-9e64-ec8b02a653c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Final Check\n",
    "\n",
    "# Recheck for any remaining missing values\n",
    "final_missing_data = df.isnull().sum().sum()\n",
    "if final_missing_data == 0:\n",
    "    print(\"Data cleaning complete. No missing values remain.\")\n",
    "else:\n",
    "    print(f\"Warning: There are still {final_missing_data} missing values in the dataset.\")\n",
    "\n",
    "# Display the final cleaned dataset\n",
    "print(\"Final cleaned dataset overview:\")\n",
    "print(df.info())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
